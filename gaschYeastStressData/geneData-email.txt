Sujet :
gene data
De :
"Kevin Murphy" <murphyk@cs.ubc.ca>
Date :
Wed, 17 Sep 2008 13:16:22 -0700
Pour :
"Francois Caron" <caronfr@cs.ubc.ca>

Here is their data. I read in the gene data using

foo=importdata('gasch00.KNNout.met.express');
names=foo.textdata; X = foo.data; save('genes.mat', 'names', 'X')
667 genes, 174 experiments.
It seems that X has not yet been standardized.

The grouping file format seems easy to understand.

With this, we should be able to reproduce the fullcov baseline and
regular L1prec for fig 4,
and show results for our ungrouped and grouped methods.

For a baseline method, you could also try using the covsrhinkFit
function, which is like their Tikhnovo regularization but sets the
lambda parameter "optimally" in closed form (see Ledoit & Wolf for
details)

K.

@article{Ledoit04a,
 title = "A Well-Conditioned Estimator for Large-Dimensional Covariance
Matrices",
 author = "O. Ledoit and M. Wolf",
 journal = "J. of Multivariate Analysis",
 volume = 88,
 number = 2,
 year = 2004,
 pages = "365--411"
}


---------- Forwarded message ----------
From: Stephen Gould <sgould@stanford.edu>
Date: Wed, Sep 17, 2008 at 12:14 PM
Subject: Re: data from your UAI08 paper
To: murphyk@cs.ubc.ca
Cc: Daphne Koller <koller@cs.stanford.edu>


Hi Kevin,

Attached is the gene dataset and manual labeling. I'll have to speak to
John about the shape dataset and get back to you shortly. The blocks for
the gene dataset are arranged as:

<# vars> <# sets>
<# vars in set 1> <list of vars in set 1>
<# vars in set 2> <list of vars in set 2>
...

There should be two variables appearing in more than one set. These were
placed in separate blocks for regularization purposes.

Thanks for pointing out the closed-form solution for choosing the
Tikhonov parameter.

Cheers,
Steve.

On Wed, 2008-09-17 at 10:54 -0700, Kevin Murphy wrote:
> > Hi
> >
> > Please can you send me the shape and gene datasets (including the
> > manual grouping into blocks) you used in your paper
> >
> > @inproceedings{Duchi08,
> >   author = {J. Duchi and S. Gould and D. Koller},
> >   title = {Projected Subgradient Methods for Learning Sparse Gaussians},
> >   booktitle = {Proceedings of the Twenty-fourth Conference on
> > Uncertainty in AI (UAI)},
> >   year = 2008,
> >  url = "http://ai.stanford.edu/~koller/Papers/Duchi+al:UAI08.pdf"
> > }
> >
> > I would like to compare our method to yours in a fair way.
> >
> > Thanks
> > Kevin
> >
> > P.S. An alternative to using CV (or test set likelihood) for selecting
> > the Tikhonov regularizer is the closed-form solution described below,
> > which you might find useful.
> >
> > @article{Ledoit04a,
> >  title = "A Well-Conditioned Estimator for Large-Dimensional Covariance
> > Matrices",
> >  author = "O. Ledoit and M. Wolf",
> >  journal = "J. of Multivariate Analysis",
> >  volume = 88,
> >  number = 2,
> >  year = 2004,
> >  pages = "365--411"
> > }
> >
> >
> > @article{Schafer05,
> >  author = "J. Schaefer and K. Strimmer",
> >  year = 2005,
> >  title = "A shrinkage approach to large-scale covariance matrix
> > estimation and implications for functional genomics",
> >  journal = "Statist. Appl. Genet. Mol. Biol",
> >  volume = 4,
> >  number = 32
> > }
--
Stephen Gould <sgould@stanford.edu> (+1-650-796-7747)
 http://www.stanford.edu/~sgould



function [s, lamcor, lamvar] = covshrinkFit(x, shrinkvar)

% Shrinkage estimate of a covariance matrix, using optimal shrinkage coefficient.
% INPUT:
% x is n*p data matrix
% shrinkvar : if 1, shrinks the diagonal variance terms, default is 0
%
% OUTPUT:
% s is the posdef p*p cov matrix
% lamcor is the shrinkage coefficient for the correlaiton matrix
% lamvar is the shrinkage coefficient for the variances
%
% See  J. Schaefer and K. Strimmer.  2005.  A shrinkage approach to 
%   large-scale covariance matrix estimation and implications 
%   for functional genomics. Statist. Appl. Genet. Mol. Biol. 4:32.
% and Opgen-Rhein, R., and K. Strimmer. 2007
%   Accurate ranking of differentially expressed genes
%   by a distribution-free shrinkage approach. Statist. Appl. Genet. Mol. Biol. To appear
% This code is based on their original code http://strimmerlab.org/software.html
% but has been vectorized and simplified by Kevin Murphy.

if nargin < 2, shrinkvar = 0; end

[n p] = size(x);
if p==1, s=var(x); return; end
if shrinkvar
  [v, lamvar] = varshrink(x);
else
  v = var(x);
  lamvar = 0;
end
dsv = diag(sqrt(v));
[r, lamcor] = corshrink(x);
s = dsv*r*dsv;

%%%%%%%%

function [sv, lambda] = varshrink (x)
% Eqns 10,11 of Opgen-Rhein and Strimmer 2007
[v, vv] = varcov(x);
v = diag(v); vv = diag(vv);
vtarget = median(v);
numerator = sum(vv);
denominator = sum((v-vtarget).^2);
lambda = numerator/denominator;
lambda = min(lambda, 1); lambda = max(lambda, 0);
sv = (1-lambda)*v + lambda*vtarget;
 
function [Rhat, lambda] = corshrink(x)
% Eqns on p4 of Schafer and Strimmer 2005
[n, p] = size(x);
sx = makeMeanZero(x); sx = makeStdOne(sx); % convert S to R
[r, vr] = varcov(sx);
offdiagsumrij2 = sum(sum(tril(r,-1).^2)); 
offdiagsumvrij = sum(sum(tril(vr,-1)));
lambda = offdiagsumvrij/offdiagsumrij2;
lambda = min(lambda, 1); lambda = max(lambda, 0);
Rhat = (1-lambda)*r;
Rhat(logical(eye(p))) = 1;

function [S, VS] = varcov(x)
% s(i,j) = cov X(i,j)
% vs(i,j) = est var s(i,j)
[n,p] = size(x);
xc = makeMeanZero(x); 
S = cov(xc);
XC1 = repmat(reshape(xc', [p 1 n]), [1 p 1]); % size p*p*n !
XC2 = repmat(reshape(xc', [1 p n]),  [p 1 1]); % size p*p*n !
VS = var(XC1 .* XC2, 0,  3) * n/((n-1)2);

function xc = makeMeanZero(x)
% make column means zero
[n,p] = size(x);
m = mean(x);
xc = x - ones(n, 1)*m; 

function xc = makeStdOne(x)
% make column  variances one
[n,p] = size(x);
sd = ones(n, 1)*std(x);
xc = x ./ sd; 


